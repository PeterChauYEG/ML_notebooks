{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Flower Classifer\n",
    "We are going to classify of flowers by species. The dataset which we will use for this toy DNN is the [Iris flower data set](https://en.wikipedia.org/wiki/Iris_flower_data_set). This is a multivariate dataset from 1936 - Ronald Fisher. There are 50 samples for each of the 3 species of Iris ((Iris setosa, Iris virginica and Iris versicolor). There are 4 features for each sample measured in cm:\n",
    "- length of sepals\n",
    "- width of sepals\n",
    "- length of petals\n",
    "- width of petals\n",
    "\n",
    "Tensorflow provides a [reference](https://www.tensorflow.org/get_started/estimator) for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dependancies\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Configure TF Logging\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Directories\n",
    "model_dir_root = '/tmp/iris'\n",
    "model_dir = os.path.join(model_dir_root, \"deep_\" + str(int(time.time())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyper Params\n",
    "batch_size = 10\n",
    "num_steps = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "IRIS_TRAINING = \"iris_training.csv\"\n",
    "IRIS_TRAINING_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "IRIS_TEST = \"iris_test.csv\"\n",
    "IRIS_TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadDataset ():\n",
    "    # If the training and test sets aren't stored locally, download them\n",
    "    if not os.path.exists(IRIS_TRAINING):\n",
    "        with urllib.request.urlopen(IRIS_TRAINING_URL) as url: \n",
    "            raw = url.read()\n",
    "        with open(IRIS_TRAINING, \"wb\") as f:\n",
    "            f.write(raw)\n",
    "\n",
    "    if not os.path.exists(IRIS_TEST):\n",
    "        with urllib.request.urlopen(IRIS_TEST_URL) as url: \n",
    "            raw = url.read()\n",
    "        with open(IRIS_TEST, \"wb\") as f:\n",
    "            f.write(raw)\n",
    "            \n",
    "    training_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "        filename=IRIS_TRAINING,\n",
    "        target_dtype=np.int,\n",
    "        features_dtype=np.float32)\n",
    "    \n",
    "    test_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "        filename=IRIS_TEST,\n",
    "        target_dtype=np.int,\n",
    "        features_dtype=np.float32)\n",
    "    \n",
    "    return training_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_data(dataset, example, all=False):\n",
    "    if all == True:\n",
    "        # log the training dataset\n",
    "        print(dataset)\n",
    "\n",
    "    # log 1 example and 1 answer\n",
    "    print(\"X: {}\".format(dataset[0][example]))\n",
    "    print(\"Y: {}\".format(dataset[1][example]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build input function\n",
    "def generate_input_fn(dataset, batch_size=batch_size):\n",
    "    def _input_fn():\n",
    "        X = tf.constant(dataset[0])\n",
    "        Y = tf.constant(dataset[1], dtype=tf.int32)\n",
    "        \n",
    "        X_batch, Y_batch = tf.train.shuffle_batch(\n",
    "            [X,Y],\n",
    "            batch_size=batch_size,\n",
    "            capacity=8*batch_size,\n",
    "            min_after_dequeue=4*batch_size,\n",
    "            enqueue_many=True\n",
    "        )\n",
    "        \n",
    "        return {'features': X_batch}, Y_batch\n",
    "    return _input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build classifier\n",
    "def define_and_run_dnn_classifier(num_steps, logdir, lr=.1, batch_size=batch_size):\n",
    "    feature_columns = [tf.contrib.layers.real_valued_column('features', dimension=4)]\n",
    "\n",
    "    classifier = tf.estimator.DNNClassifier(\n",
    "        feature_columns=feature_columns,\n",
    "        n_classes=3,\n",
    "        hidden_units=[10,10,10],\n",
    "        optimizer=tf.train.ProximalAdagradOptimizer(learning_rate=lr),\n",
    "        model_dir=logdir\n",
    "    )\n",
    "    \n",
    "    # Train classifer\n",
    "    classifier.train(\n",
    "        input_fn=generate_input_fn(\n",
    "            training_set,\n",
    "            batch_size=batch_size\n",
    "        ),\n",
    "        steps=num_steps\n",
    "    )\n",
    "    \n",
    "    print(\"Finished running the deep training\")\n",
    "    print(\"evaluating DNN classifier accuracy\")\n",
    "    \n",
    "    # Test classifer\n",
    "    accuracy_score = classifier.evaluate(\n",
    "        input_fn=generate_input_fn(\n",
    "            test_set,\n",
    "            batch_size=batch_size\n",
    "        ),\n",
    "        steps=100\n",
    "    )['accuracy']\n",
    "    \n",
    "    print(\"DNN classifier accuracy: {0:f}\".format(accuracy_score))\n",
    "    \n",
    "    # Make a prediction\n",
    "    predictions = classifier.predict(\n",
    "        input_fn=generate_input_fn(\n",
    "            test_set,\n",
    "            batch_size=1\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # make a prediction\n",
    "    print(\"DNN classifier prediction: \")\n",
    "    for i in range(10):\n",
    "        prediction = predictions.__next__()['probabilities']\n",
    "        print(\"\\nPrediction for example {0}: {1}\".format(i, np.argmax(prediction)))\n",
    "        log_data(training_set, i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: [ 6.4000001   2.79999995  5.5999999   2.20000005]\n",
      "Y: 2\n"
     ]
    }
   ],
   "source": [
    "# Run classifer\n",
    "training_set, test_set = loadDataset()\n",
    "\n",
    "# log an example\n",
    "log_data(training_set, 0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DNN Classifier\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/iris/deep_1506291613', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/iris/deep_1506291613/model.ckpt.\n",
      "INFO:tensorflow:loss = 338.673, step = 1\n",
      "INFO:tensorflow:global_step/sec: 760.048\n",
      "INFO:tensorflow:loss = 10.5828, step = 101 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 737.997\n",
      "INFO:tensorflow:loss = 10.4437, step = 201 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 727.505\n",
      "INFO:tensorflow:loss = 4.60491, step = 301 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 732.887\n",
      "INFO:tensorflow:loss = 1.56145, step = 401 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 722.685\n",
      "INFO:tensorflow:loss = 4.67731, step = 501 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 724.645\n",
      "INFO:tensorflow:loss = 7.83535, step = 601 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 748.566\n",
      "INFO:tensorflow:loss = 3.77556, step = 701 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 739.585\n",
      "INFO:tensorflow:loss = 6.59535, step = 801 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 738.834\n",
      "INFO:tensorflow:loss = 2.80143, step = 901 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 721.917\n",
      "INFO:tensorflow:loss = 0.67693, step = 1001 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.747\n",
      "INFO:tensorflow:loss = 4.70369, step = 1101 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 735.565\n",
      "INFO:tensorflow:loss = 7.79125, step = 1201 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 723.947\n",
      "INFO:tensorflow:loss = 4.19748, step = 1301 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 710.7\n",
      "INFO:tensorflow:loss = 3.09186, step = 1401 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 741.367\n",
      "INFO:tensorflow:loss = 5.71863, step = 1501 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 729.582\n",
      "INFO:tensorflow:loss = 4.23264, step = 1601 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 699.16\n",
      "INFO:tensorflow:loss = 1.54179, step = 1701 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 739.333\n",
      "INFO:tensorflow:loss = 11.1943, step = 1801 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 726.841\n",
      "INFO:tensorflow:loss = 2.60286, step = 1901 (0.138 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into /tmp/iris/deep_1506291613/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4.21756.\n",
      "Finished running the deep training\n",
      "evaluating DNN classifier accuracy\n",
      "INFO:tensorflow:Starting evaluation at 2017-09-24-22:20:30\n",
      "INFO:tensorflow:Restoring parameters from /tmp/iris/deep_1506291613/model.ckpt-2000\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "INFO:tensorflow:Evaluation [5/100]\n",
      "INFO:tensorflow:Evaluation [6/100]\n",
      "INFO:tensorflow:Evaluation [7/100]\n",
      "INFO:tensorflow:Evaluation [8/100]\n",
      "INFO:tensorflow:Evaluation [9/100]\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [11/100]\n",
      "INFO:tensorflow:Evaluation [12/100]\n",
      "INFO:tensorflow:Evaluation [13/100]\n",
      "INFO:tensorflow:Evaluation [14/100]\n",
      "INFO:tensorflow:Evaluation [15/100]\n",
      "INFO:tensorflow:Evaluation [16/100]\n",
      "INFO:tensorflow:Evaluation [17/100]\n",
      "INFO:tensorflow:Evaluation [18/100]\n",
      "INFO:tensorflow:Evaluation [19/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [21/100]\n",
      "INFO:tensorflow:Evaluation [22/100]\n",
      "INFO:tensorflow:Evaluation [23/100]\n",
      "INFO:tensorflow:Evaluation [24/100]\n",
      "INFO:tensorflow:Evaluation [25/100]\n",
      "INFO:tensorflow:Evaluation [26/100]\n",
      "INFO:tensorflow:Evaluation [27/100]\n",
      "INFO:tensorflow:Evaluation [28/100]\n",
      "INFO:tensorflow:Evaluation [29/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [31/100]\n",
      "INFO:tensorflow:Evaluation [32/100]\n",
      "INFO:tensorflow:Evaluation [33/100]\n",
      "INFO:tensorflow:Evaluation [34/100]\n",
      "INFO:tensorflow:Evaluation [35/100]\n",
      "INFO:tensorflow:Evaluation [36/100]\n",
      "INFO:tensorflow:Evaluation [37/100]\n",
      "INFO:tensorflow:Evaluation [38/100]\n",
      "INFO:tensorflow:Evaluation [39/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [41/100]\n",
      "INFO:tensorflow:Evaluation [42/100]\n",
      "INFO:tensorflow:Evaluation [43/100]\n",
      "INFO:tensorflow:Evaluation [44/100]\n",
      "INFO:tensorflow:Evaluation [45/100]\n",
      "INFO:tensorflow:Evaluation [46/100]\n",
      "INFO:tensorflow:Evaluation [47/100]\n",
      "INFO:tensorflow:Evaluation [48/100]\n",
      "INFO:tensorflow:Evaluation [49/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [51/100]\n",
      "INFO:tensorflow:Evaluation [52/100]\n",
      "INFO:tensorflow:Evaluation [53/100]\n",
      "INFO:tensorflow:Evaluation [54/100]\n",
      "INFO:tensorflow:Evaluation [55/100]\n",
      "INFO:tensorflow:Evaluation [56/100]\n",
      "INFO:tensorflow:Evaluation [57/100]\n",
      "INFO:tensorflow:Evaluation [58/100]\n",
      "INFO:tensorflow:Evaluation [59/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [61/100]\n",
      "INFO:tensorflow:Evaluation [62/100]\n",
      "INFO:tensorflow:Evaluation [63/100]\n",
      "INFO:tensorflow:Evaluation [64/100]\n",
      "INFO:tensorflow:Evaluation [65/100]\n",
      "INFO:tensorflow:Evaluation [66/100]\n",
      "INFO:tensorflow:Evaluation [67/100]\n",
      "INFO:tensorflow:Evaluation [68/100]\n",
      "INFO:tensorflow:Evaluation [69/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [71/100]\n",
      "INFO:tensorflow:Evaluation [72/100]\n",
      "INFO:tensorflow:Evaluation [73/100]\n",
      "INFO:tensorflow:Evaluation [74/100]\n",
      "INFO:tensorflow:Evaluation [75/100]\n",
      "INFO:tensorflow:Evaluation [76/100]\n",
      "INFO:tensorflow:Evaluation [77/100]\n",
      "INFO:tensorflow:Evaluation [78/100]\n",
      "INFO:tensorflow:Evaluation [79/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [81/100]\n",
      "INFO:tensorflow:Evaluation [82/100]\n",
      "INFO:tensorflow:Evaluation [83/100]\n",
      "INFO:tensorflow:Evaluation [84/100]\n",
      "INFO:tensorflow:Evaluation [85/100]\n",
      "INFO:tensorflow:Evaluation [86/100]\n",
      "INFO:tensorflow:Evaluation [87/100]\n",
      "INFO:tensorflow:Evaluation [88/100]\n",
      "INFO:tensorflow:Evaluation [89/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [91/100]\n",
      "INFO:tensorflow:Evaluation [92/100]\n",
      "INFO:tensorflow:Evaluation [93/100]\n",
      "INFO:tensorflow:Evaluation [94/100]\n",
      "INFO:tensorflow:Evaluation [95/100]\n",
      "INFO:tensorflow:Evaluation [96/100]\n",
      "INFO:tensorflow:Evaluation [97/100]\n",
      "INFO:tensorflow:Evaluation [98/100]\n",
      "INFO:tensorflow:Evaluation [99/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-24-22:20:31\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.9666, average_loss = 0.0699385, global_step = 2000, loss = 6.99385\n",
      "DNN classifier accuracy: 0.966600\n",
      "DNN classifier prediction: \n",
      "INFO:tensorflow:Restoring parameters from /tmp/iris/deep_1506291613/model.ckpt-2000\n",
      "\n",
      "Prediction for example 0: 2\n",
      "X: [ 6.4000001   2.79999995  5.5999999   2.20000005]\n",
      "Y: 2\n",
      "\n",
      "Prediction for example 1: 1\n",
      "X: [ 5.          2.29999995  3.29999995  1.        ]\n",
      "Y: 1\n",
      "\n",
      "Prediction for example 2: 0\n",
      "X: [ 4.9000001   2.5         4.5         1.70000005]\n",
      "Y: 2\n",
      "\n",
      "Prediction for example 3: 2\n",
      "X: [ 4.9000001  3.0999999  1.5        0.1      ]\n",
      "Y: 0\n",
      "\n",
      "Prediction for example 4: 1\n",
      "X: [ 5.69999981  3.79999995  1.70000005  0.30000001]\n",
      "Y: 0\n",
      "\n",
      "Prediction for example 5: 1\n",
      "X: [ 4.4000001   3.20000005  1.29999995  0.2       ]\n",
      "Y: 0\n",
      "\n",
      "Prediction for example 6: 2\n",
      "X: [ 5.4000001   3.4000001   1.5         0.40000001]\n",
      "Y: 0\n",
      "\n",
      "Prediction for example 7: 0\n",
      "X: [ 6.9000001   3.0999999   5.0999999   2.29999995]\n",
      "Y: 2\n",
      "\n",
      "Prediction for example 8: 1\n",
      "X: [ 6.69999981  3.0999999   4.4000001   1.39999998]\n",
      "Y: 1\n",
      "\n",
      "Prediction for example 9: 2\n",
      "X: [ 5.0999999   3.70000005  1.5         0.40000001]\n",
      "Y: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Running DNN Classifier\")\n",
    "define_and_run_dnn_classifier(\n",
    "    num_steps,\n",
    "    model_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
