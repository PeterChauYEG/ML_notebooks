{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low Birth Weight\n",
    "\n",
    "## [Data](http://www.statlab.uni-heidelberg.de/data/linmod/birthweight.html)\n",
    "There is a birth weight dataset with 189 entires. These rows include 1 label as to weither the baby has a low birth weight, and 9 features.\n",
    "\n",
    "## Goal\n",
    "We want to classify an example with 9 features into low birth weight or not. Low birthweight is < 2.5kg\n",
    "\n",
    "## Methodology\n",
    "We are going to use a DNN classifier to solve this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dependancies\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import collections\n",
    "import time\n",
    "import numpy as np\n",
    "import requests\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Configure TF Logging\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Directories\n",
    "model_dir_root = '/tmp/low_birthweight'\n",
    "model_dir = os.path.join(model_dir_root, \"deep_\" + str(int(time.time())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyper Params\n",
    "batch_size = 8\n",
    "num_steps = 2000\n",
    "Dataset = collections.namedtuple('Dataset', ['data', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "birth_weight_file = 'birth_weight.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_dataset ():\n",
    "    # download data and create data file if file does not exist in current directory\n",
    "    if not os.path.exists(birth_weight_file):\n",
    "        birthdata_url = 'https://github.com/nfmcclure/tensorflow_cookbook/raw/master/01_Introduction/07_Working_with_Data_Sources/birthweight_data/birthweight.dat'\n",
    "        birth_file = requests.get(birthdata_url)\n",
    "        birth_data = birth_file.text.split('\\r\\n')\n",
    "        birth_header = birth_data[1].split('\\t')\n",
    "        birth_data = [[float(x) for x in y.split('\\t') if len(x)>=1] for y in birth_data[1:] if len(y)>=1]\n",
    "        with open(birth_weight_file, \"w\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerows(birth_data)\n",
    "            f.close()\n",
    "\n",
    "    # read birth weight data into memory\n",
    "    birth_data = []\n",
    "    with open(birth_weight_file, newline='') as csvfile:\n",
    "         csv_reader = csv.reader(csvfile)\n",
    "         birth_header = next(csv_reader)\n",
    "         for row in csv_reader:\n",
    "             birth_data.append(row)\n",
    "\n",
    "    birth_data = [[float(x) for x in row] for row in birth_data]\n",
    "\n",
    "    # Pull out target variable\n",
    "    y_vals = np.array([x[0] for x in birth_data])\n",
    "    # Pull out predictor variables (not id, not target, and not birthweight)\n",
    "    x_vals = np.array([x[1:9] for x in birth_data])\n",
    "\n",
    "    # set for reproducible results\n",
    "    seed = 99\n",
    "    np.random.seed(seed)\n",
    "    tf.set_random_seed(seed)\n",
    "\n",
    "    # Split data into train/test = 80%/20%\n",
    "    train_indices = np.random.choice(len(x_vals), round(len(x_vals)*0.8), replace=False)\n",
    "    test_indices = np.array(list(set(range(len(x_vals))) - set(train_indices)))\n",
    "    x_vals_train = x_vals[train_indices]\n",
    "    x_vals_test = x_vals[test_indices]\n",
    "    y_vals_train = y_vals[train_indices]\n",
    "    y_vals_test = y_vals[test_indices]\n",
    "    \n",
    "    # Create training_set Database Object\n",
    "    train_target = np.array(y_vals_train, dtype=np.int)\n",
    "    train_data = np.array(x_vals_train)\n",
    "    training_set = Dataset(data=train_data, target=train_target)\n",
    "    \n",
    "    # Create test_set Database Object\n",
    "    test_target = np.array(y_vals_test, dtype=np.int)\n",
    "    test_data = np.array(x_vals_test)\n",
    "    test_set = Dataset(data=test_data, target=test_target)    \n",
    "    \n",
    "    return training_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_data(dataset, example, all=False):\n",
    "    if all == True:\n",
    "        # log the training dataset\n",
    "        print(dataset)\n",
    "\n",
    "    # log 1 example and 1 answer\n",
    "    print(\"X: {}\".format(dataset[0][example]))\n",
    "    print(\"Y: {}\".format(dataset[1][example]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build input function\n",
    "def generate_input_fn(dataset, batch_size=batch_size):\n",
    "    def _input_fn():\n",
    "        X = tf.constant(dataset[0])\n",
    "        Y = tf.constant(dataset[1], dtype=tf.int32)\n",
    "        \n",
    "        X_batch, Y_batch = tf.train.shuffle_batch(\n",
    "            [X,Y],\n",
    "            batch_size=batch_size,\n",
    "            capacity=3*batch_size,\n",
    "            min_after_dequeue=2*batch_size,\n",
    "            enqueue_many=True\n",
    "        )\n",
    "        \n",
    "        return {'features': X_batch}, Y_batch\n",
    "    return _input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build classifier\n",
    "def define_and_run_dnn_classifier(num_steps, logdir, lr=.1, batch_size=batch_size):\n",
    "    feature_columns = [tf.contrib.layers.real_valued_column('features', dimension=8)]\n",
    "\n",
    "#     linear classifier    \n",
    "#     classifier = tf.estimator.LinearClassifier(\n",
    "#         feature_columns=feature_columns,\n",
    "#         model_dir=logdir,\n",
    "#         n_classes=2,\n",
    "#         optimizer='Ftrl',\n",
    "#     )\n",
    "    \n",
    "#     DNN Classifier\n",
    "    classifier = tf.estimator.DNNClassifier(\n",
    "        feature_columns=feature_columns,\n",
    "        n_classes=2,\n",
    "        hidden_units=[5,5,5],\n",
    "        optimizer=tf.train.ProximalAdagradOptimizer(learning_rate=lr),\n",
    "        model_dir=logdir\n",
    "    )\n",
    "    \n",
    "    # Train classifer\n",
    "    classifier.train(\n",
    "        input_fn=generate_input_fn(\n",
    "            training_set,\n",
    "            batch_size=batch_size\n",
    "        ),\n",
    "        steps=num_steps\n",
    "    )\n",
    "    \n",
    "    print(\"Finished running the deep training\")\n",
    "    print(\"evaluating DNN classifier accuracy\")\n",
    "    \n",
    "    # Test classifer\n",
    "    accuracy_score = classifier.evaluate(\n",
    "        input_fn=generate_input_fn(\n",
    "            test_set,\n",
    "            batch_size=batch_size\n",
    "        ),\n",
    "        steps=100\n",
    "    )['accuracy']\n",
    "    \n",
    "    print(\"DNN classifier accuracy: {0:f}\".format(accuracy_score))\n",
    "    \n",
    "    # Make a prediction\n",
    "    predictions = classifier.predict(\n",
    "        input_fn=generate_input_fn(\n",
    "            test_set,\n",
    "            batch_size=1\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # make a prediction\n",
    "    print(\"DNN classifier prediction: \")\n",
    "    for i in range(10):\n",
    "        prediction = predictions.__next__()['probabilities']\n",
    "        print(\"\\nPrediction for example {0}: {1}\".format(i, np.argmax(prediction)))\n",
    "        log_data(training_set, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: [  2.00000000e+01   1.05000000e+02   1.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   2.45000000e+03]\n",
      "Y: 1\n"
     ]
    }
   ],
   "source": [
    "training_set, test_set = construct_dataset()\n",
    "\n",
    "# log an example\n",
    "log_data(training_set, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DNN Classifier\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/low_birthweight/deep_1507002346', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/low_birthweight/deep_1507002346/model.ckpt.\n",
      "INFO:tensorflow:loss = 548.925, step = 1\n",
      "INFO:tensorflow:global_step/sec: 753.114\n",
      "INFO:tensorflow:loss = 3.10185, step = 101 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 720.369\n",
      "INFO:tensorflow:loss = 6.16866, step = 201 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 888.757\n",
      "INFO:tensorflow:loss = 6.18308, step = 301 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 847.791\n",
      "INFO:tensorflow:loss = 2.94545, step = 401 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 684.627\n",
      "INFO:tensorflow:loss = 5.37306, step = 501 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 650.753\n",
      "INFO:tensorflow:loss = 5.37453, step = 601 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.189\n",
      "INFO:tensorflow:loss = 3.73882, step = 701 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 703.798\n",
      "INFO:tensorflow:loss = 4.56319, step = 801 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 766.237\n",
      "INFO:tensorflow:loss = 7.0112, step = 901 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 818.492\n",
      "INFO:tensorflow:loss = 3.73783, step = 1001 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 796.447\n",
      "INFO:tensorflow:loss = 3.75476, step = 1101 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 756.711\n",
      "INFO:tensorflow:loss = 3.75807, step = 1201 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 856.104\n",
      "INFO:tensorflow:loss = 5.38247, step = 1301 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 848.064\n",
      "INFO:tensorflow:loss = 5.37673, step = 1401 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 849.903\n",
      "INFO:tensorflow:loss = 4.56376, step = 1501 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 830.871\n",
      "INFO:tensorflow:loss = 3.74427, step = 1601 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 796.765\n",
      "INFO:tensorflow:loss = 4.56183, step = 1701 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 789.431\n",
      "INFO:tensorflow:loss = 3.74477, step = 1801 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 761.525\n",
      "INFO:tensorflow:loss = 4.56086, step = 1901 (0.131 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into /tmp/low_birthweight/deep_1507002346/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4.56309.\n",
      "Finished running the deep training\n",
      "evaluating DNN classifier accuracy\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-03-03:46:10\n",
      "INFO:tensorflow:Restoring parameters from /tmp/low_birthweight/deep_1507002346/model.ckpt-2000\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Evaluation [4/100]\n",
      "INFO:tensorflow:Evaluation [5/100]\n",
      "INFO:tensorflow:Evaluation [6/100]\n",
      "INFO:tensorflow:Evaluation [7/100]\n",
      "INFO:tensorflow:Evaluation [8/100]\n",
      "INFO:tensorflow:Evaluation [9/100]\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [11/100]\n",
      "INFO:tensorflow:Evaluation [12/100]\n",
      "INFO:tensorflow:Evaluation [13/100]\n",
      "INFO:tensorflow:Evaluation [14/100]\n",
      "INFO:tensorflow:Evaluation [15/100]\n",
      "INFO:tensorflow:Evaluation [16/100]\n",
      "INFO:tensorflow:Evaluation [17/100]\n",
      "INFO:tensorflow:Evaluation [18/100]\n",
      "INFO:tensorflow:Evaluation [19/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [21/100]\n",
      "INFO:tensorflow:Evaluation [22/100]\n",
      "INFO:tensorflow:Evaluation [23/100]\n",
      "INFO:tensorflow:Evaluation [24/100]\n",
      "INFO:tensorflow:Evaluation [25/100]\n",
      "INFO:tensorflow:Evaluation [26/100]\n",
      "INFO:tensorflow:Evaluation [27/100]\n",
      "INFO:tensorflow:Evaluation [28/100]\n",
      "INFO:tensorflow:Evaluation [29/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [31/100]\n",
      "INFO:tensorflow:Evaluation [32/100]\n",
      "INFO:tensorflow:Evaluation [33/100]\n",
      "INFO:tensorflow:Evaluation [34/100]\n",
      "INFO:tensorflow:Evaluation [35/100]\n",
      "INFO:tensorflow:Evaluation [36/100]\n",
      "INFO:tensorflow:Evaluation [37/100]\n",
      "INFO:tensorflow:Evaluation [38/100]\n",
      "INFO:tensorflow:Evaluation [39/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [41/100]\n",
      "INFO:tensorflow:Evaluation [42/100]\n",
      "INFO:tensorflow:Evaluation [43/100]\n",
      "INFO:tensorflow:Evaluation [44/100]\n",
      "INFO:tensorflow:Evaluation [45/100]\n",
      "INFO:tensorflow:Evaluation [46/100]\n",
      "INFO:tensorflow:Evaluation [47/100]\n",
      "INFO:tensorflow:Evaluation [48/100]\n",
      "INFO:tensorflow:Evaluation [49/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [51/100]\n",
      "INFO:tensorflow:Evaluation [52/100]\n",
      "INFO:tensorflow:Evaluation [53/100]\n",
      "INFO:tensorflow:Evaluation [54/100]\n",
      "INFO:tensorflow:Evaluation [55/100]\n",
      "INFO:tensorflow:Evaluation [56/100]\n",
      "INFO:tensorflow:Evaluation [57/100]\n",
      "INFO:tensorflow:Evaluation [58/100]\n",
      "INFO:tensorflow:Evaluation [59/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [61/100]\n",
      "INFO:tensorflow:Evaluation [62/100]\n",
      "INFO:tensorflow:Evaluation [63/100]\n",
      "INFO:tensorflow:Evaluation [64/100]\n",
      "INFO:tensorflow:Evaluation [65/100]\n",
      "INFO:tensorflow:Evaluation [66/100]\n",
      "INFO:tensorflow:Evaluation [67/100]\n",
      "INFO:tensorflow:Evaluation [68/100]\n",
      "INFO:tensorflow:Evaluation [69/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [71/100]\n",
      "INFO:tensorflow:Evaluation [72/100]\n",
      "INFO:tensorflow:Evaluation [73/100]\n",
      "INFO:tensorflow:Evaluation [74/100]\n",
      "INFO:tensorflow:Evaluation [75/100]\n",
      "INFO:tensorflow:Evaluation [76/100]\n",
      "INFO:tensorflow:Evaluation [77/100]\n",
      "INFO:tensorflow:Evaluation [78/100]\n",
      "INFO:tensorflow:Evaluation [79/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [81/100]\n",
      "INFO:tensorflow:Evaluation [82/100]\n",
      "INFO:tensorflow:Evaluation [83/100]\n",
      "INFO:tensorflow:Evaluation [84/100]\n",
      "INFO:tensorflow:Evaluation [85/100]\n",
      "INFO:tensorflow:Evaluation [86/100]\n",
      "INFO:tensorflow:Evaluation [87/100]\n",
      "INFO:tensorflow:Evaluation [88/100]\n",
      "INFO:tensorflow:Evaluation [89/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [91/100]\n",
      "INFO:tensorflow:Evaluation [92/100]\n",
      "INFO:tensorflow:Evaluation [93/100]\n",
      "INFO:tensorflow:Evaluation [94/100]\n",
      "INFO:tensorflow:Evaluation [95/100]\n",
      "INFO:tensorflow:Evaluation [96/100]\n",
      "INFO:tensorflow:Evaluation [97/100]\n",
      "INFO:tensorflow:Evaluation [98/100]\n",
      "INFO:tensorflow:Evaluation [99/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-03-03:46:10\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.68, accuracy_baseline = 0.68, auc = 0.5, auc_precision_recall = 0.66, average_loss = 0.627251, global_step = 2000, label/mean = 0.32, loss = 5.01801, prediction/mean = 0.307206\n",
      "DNN classifier accuracy: 0.680000\n",
      "DNN classifier prediction: \n",
      "INFO:tensorflow:Restoring parameters from /tmp/low_birthweight/deep_1507002346/model.ckpt-2000\n",
      "\n",
      "Prediction for example 0: 0\n",
      "X: [  2.00000000e+01   1.05000000e+02   1.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   2.45000000e+03]\n",
      "Y: 1\n",
      "\n",
      "Prediction for example 1: 0\n",
      "X: [  1.70000000e+01   1.30000000e+02   1.00000000e+00   1.00000000e+00\n",
      "   1.00000000e+00   0.00000000e+00   1.00000000e+00   2.12500000e+03]\n",
      "Y: 1\n",
      "\n",
      "Prediction for example 2: 0\n",
      "X: [   31.   120.     0.     0.     0.     0.     0.  4167.]\n",
      "Y: 0\n",
      "\n",
      "Prediction for example 3: 0\n",
      "X: [  1.80000000e+01   9.00000000e+01   0.00000000e+00   1.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   1.00000000e+00   3.07600000e+03]\n",
      "Y: 0\n",
      "\n",
      "Prediction for example 4: 0\n",
      "X: [  2.30000000e+01   1.20000000e+02   1.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   2.39500000e+03]\n",
      "Y: 1\n",
      "\n",
      "Prediction for example 5: 0\n",
      "X: [  2.00000000e+01   1.22000000e+02   1.00000000e+00   1.00000000e+00\n",
      "   1.00000000e+00   0.00000000e+00   0.00000000e+00   2.38100000e+03]\n",
      "Y: 1\n",
      "\n",
      "Prediction for example 6: 0\n",
      "X: [  1.80000000e+01   9.00000000e+01   0.00000000e+00   1.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   1.00000000e+00   3.07600000e+03]\n",
      "Y: 0\n",
      "\n",
      "Prediction for example 7: 0\n",
      "X: [  1.90000000e+01   1.05000000e+02   1.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   3.57200000e+03]\n",
      "Y: 0\n",
      "\n",
      "Prediction for example 8: 0\n",
      "X: [  3.20000000e+01   1.05000000e+02   1.00000000e+00   1.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   1.81800000e+03]\n",
      "Y: 1\n",
      "\n",
      "Prediction for example 9: 0\n",
      "X: [  1.70000000e+01   1.20000000e+02   0.00000000e+00   1.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   2.41400000e+03]\n",
      "Y: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Running DNN Classifier\")\n",
    "define_and_run_dnn_classifier(\n",
    "    num_steps,\n",
    "    model_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tensorboard --logdir=/tmp/low_birthweights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
